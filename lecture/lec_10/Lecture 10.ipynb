{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 10 Introduction to Machine Learning and Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivating Example: Single-variable (1D) Linear Regression\n",
    "\n",
    "### **Problem**\n",
    "Given the *training dataset* $(x^{(i)}\\in\\mathbb{R},y^{(i)}\\in\\mathbb{R}), i= 1,2,..., N$, we want to find the linear function $$y\\approx f(x)=wx +b$$ that fits the relations between $x^{(i)}$ and $y^{(i)}$. So that given any new $x^{test}$ in the **test** dataset, we can make the prediction $$y^{pred} = w x^{test}+b$$\n",
    "\n",
    "### Training the model\n",
    "\n",
    "- With the training dataset, define the loss function $L(w,b)$ of parameter $w$ and $b$, which is also called **mean squared error** (MSE) $$L(w,b)=\\frac{1}{N}\\sum_{i=1}^N\\big(\\hat{y}^{(i)}-y^{(i)}\\big)^2=\\frac{1}{N}\\sum_{i=1}^N\\big((wx^{(i)}+b)-y^{(i)}\\big)^2,$$ where $\\hat{y}^{(i)}$ denotes the predicted value of y at $x^{(i)}$, i.e. $\\hat{y}^{(i)} = wx^{(i)}+b$.\n",
    "\n",
    "\n",
    "- Then find the minimum of loss function -- note that this is the quadratic function of $w$ and $b$, and we can analytically solve $\\partial_{w}L = \\partial_{b}L =0$, and yields\n",
    "\n",
    "$$ w^* =\\frac{\\sum_{i=1}^{N}(x_{i}-\\bar{x})(y_{i}-\\bar{y})}{\\sum_{i=1}^{N}(x_{i}-\\bar{x})^{2}} = \\frac{\\frac{1}{N}\\sum_{i=1}^{N}(x_{i}-\\bar{x})(y_{i}-\\bar{y})}{\\frac{1}{N}\\sum_{i=1}^{N}(x_{i}-\\bar{x})^{2}} = \\frac{\\text{Cov}(X,Y)}{\\text{Var}(X)},$$\n",
    "\n",
    "$$ b^* = \\bar{y}  - w^*\\bar{x},$$\n",
    "\n",
    "where $\\bar{x}$ and $\\bar{y}$ are the mean of $x$ and of $y$, and $\\text{Cov}(X,Y)$ denotes the estimated covariance (or called sample covariance) between $X$ and $Y$ (a little difference with what you learned in statistics is that we have the normalization factor $1/N$ instead of $1/(N-1)$ here), and $\\text{Var}(Y)$ denotes the sample variance of $Y$ (the normalization factor is still $1/N$). This is just about convention -- in statistics, they pursue for unbiased estimator.\n",
    "\n",
    "### Evaluating the model\n",
    "\n",
    "- MSE: The smaller MSE indicates better performance\n",
    "- R-Squared: The larger $R^{2}$ (closer to 1) indicates better performance. Compared with MSE, R-squared is **dimensionless**, not dependent on the units of variable. \n",
    "\n",
    "$$R^{2} = 1 - \\frac{\\sum_{i=1}^{N}(y^{(i)}-\\hat{y}^{(i)})^{2}}{\\sum_{i=1}^{N}(y^{(i)}-\\bar{y})^{2}} = 1 - \\frac{\\frac{1}{N}\\sum_{i=1}^{N}(y^{(i)}-\\hat{y}^{(i)})^{2}}{\\frac{1}{N}\\sum_{i=1}^{N}(y^{(i)}-\\bar{y})^{2}} = 1 - \\frac{\\text{MSE}}{\\text{Var}(Y)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MyLinearRegression1D:\n",
    "    '''\n",
    "    The single-variable linear regression estimator -- writing in the style of sklearn package\n",
    "    '''\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        '''\n",
    "        Determine the optimal parameters w, b for the input data x and y\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "           x : 1D numpy array with shape (n_samples,) from training data\n",
    "           y : 1D numpy array with shape (n_samples,) from training data\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self : returns an instance of self, with new attributes slope w (float) and intercept b (float)\n",
    "         '''\n",
    "        \n",
    "        cov_mat = np.cov(x,y,bias=True) # covariance matrix, bias = True makes the factor is 1/N -- but it doesn't matter actually, since the factor will be cancelled\n",
    "        self.w = cov_mat[0,1] / cov_mat[0,0] # the (0,1) element is COV(X,Y) and (0,0) element is Var(X). (1,1) is Var(Y)\n",
    "        self.b =  np.mean(y)-self.w * np.mean(x)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        '''\n",
    "        Predict the output values for the input value x, based on trained parameters\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "           x : 1D numpy array from training or test data \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        returns 1D numpy array of same shape as input, the predicted y value of corresponding x\n",
    "        '''\n",
    "        \n",
    "        return self.w*x+self.b\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        '''\n",
    "        Calculate the R-squared on the dataset with input x and y\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "           x : 1D numpy array with shape (n_samples,) from training or test data\n",
    "           y : 1D numpy array with shape (n_samples,) from training or test data\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        returns float, the R^2 value\n",
    "        '''\n",
    "        \n",
    "        y_hat = self.predict (x) # predicted y\n",
    "        mse = np.mean((y-y_hat)**2) # mean squared error\n",
    "        return 1- mse / np.var(y) # return R-squared\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "X, y = datasets.load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x17ee9c8e188>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X[:,5],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on MyLinearRegression1D in module __main__ object:\n",
      "\n",
      "class MyLinearRegression1D(builtins.object)\n",
      " |  The single-variable linear regression estimator -- writing in the style of sklearn package\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  fit(self, x, y)\n",
      " |      Determine the optimal parameters w, b for the input data x and y\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |         x : 1D numpy array with shape (n_samples,) from training data\n",
      " |         y : 1D numpy array with shape (n_samples,) from training data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns an instance of self, with new attributes slope w (float) and intercept b (float)\n",
      " |  \n",
      " |  predict(self, x)\n",
      " |      Predict the output values for the input value x, based on trained parameters\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |         x : 1D numpy array from training or test data \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      returns 1D numpy array of same shape as input, the predicted y value of corresponding x\n",
      " |  \n",
      " |  score(self, x, y)\n",
      " |      Calculate the R-squared on the dataset with input x and y\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |         x : 1D numpy array with shape (n_samples,) from training or test data\n",
      " |         y : 1D numpy array with shape (n_samples,) from training or test data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      returns float, the R^2 value\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lreg = MyLinearRegression1D() # initialize the instance of one estimator\n",
    "help(lreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg.fit(X[:,5],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4835254559913341"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg.score(X[:,5],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17ee9e22848>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(dpi = 100)\n",
    "plt.scatter(X[:,5],y)\n",
    "plt.plot(X[:,5],lreg.predict(X[:,5]),'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model # compare with the scikit learn package\n",
    "lreg_sklearn = linear_model.LinearRegression()\n",
    "lreg_sklearn.fit(X[:,5].reshape(-1,1),y) #only accept 2D-array as x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.102108981180306 -34.67062077643854\n",
      "[9.10210898] -34.67062077643857\n"
     ]
    }
   ],
   "source": [
    "print(lreg.w,lreg.b)\n",
    "print(lreg_sklearn.coef_, lreg_sklearn.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4835254559913343"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg_sklearn.score(X[:,5].reshape(-1,1),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LinearRegression in module sklearn.linear_model.base object:\n",
      "\n",
      "class LinearRegression(LinearModel, sklearn.base.RegressorMixin, sklearn.base.MultiOutputMixin)\n",
      " |  LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
      " |  \n",
      " |  Ordinary least squares Linear Regression.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  fit_intercept : boolean, optional, default True\n",
      " |      whether to calculate the intercept for this model. If set\n",
      " |      to False, no intercept will be used in calculations\n",
      " |      (e.g. data is expected to be already centered).\n",
      " |  \n",
      " |  normalize : boolean, optional, default False\n",
      " |      This parameter is ignored when ``fit_intercept`` is set to False.\n",
      " |      If True, the regressors X will be normalized before regression by\n",
      " |      subtracting the mean and dividing by the l2-norm.\n",
      " |      If you wish to standardize, please use\n",
      " |      :class:`sklearn.preprocessing.StandardScaler` before calling ``fit`` on\n",
      " |      an estimator with ``normalize=False``.\n",
      " |  \n",
      " |  copy_X : boolean, optional, default True\n",
      " |      If True, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      The number of jobs to use for the computation. This will only provide\n",
      " |      speedup for n_targets > 1 and sufficient large problems.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : array, shape (n_features, ) or (n_targets, n_features)\n",
      " |      Estimated coefficients for the linear regression problem.\n",
      " |      If multiple targets are passed during the fit (y 2D), this\n",
      " |      is a 2D array of shape (n_targets, n_features), while if only\n",
      " |      one target is passed, this is a 1D array of length n_features.\n",
      " |  \n",
      " |  intercept_ : array\n",
      " |      Independent term in the linear model.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.linear_model import LinearRegression\n",
      " |  >>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
      " |  >>> # y = 1 * x_0 + 2 * x_1 + 3\n",
      " |  >>> y = np.dot(X, np.array([1, 2])) + 3\n",
      " |  >>> reg = LinearRegression().fit(X, y)\n",
      " |  >>> reg.score(X, y)\n",
      " |  1.0\n",
      " |  >>> reg.coef_\n",
      " |  array([1., 2.])\n",
      " |  >>> reg.intercept_ # doctest: +ELLIPSIS\n",
      " |  3.0000...\n",
      " |  >>> reg.predict(np.array([[3, 5]]))\n",
      " |  array([16.])\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  From the implementation point of view, this is just plain Ordinary\n",
      " |  Least Squares (scipy.linalg.lstsq) wrapped as a predictor object.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LinearRegression\n",
      " |      LinearModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Training data\n",
      " |      \n",
      " |      y : array_like, shape (n_samples, n_targets)\n",
      " |          Target values. Will be cast to X's dtype if necessary\n",
      " |      \n",
      " |      sample_weight : numpy array of shape [n_samples]\n",
      " |          Individual weights for each sample\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             parameter *sample_weight* support to LinearRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns an instance of self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a\n",
      " |          precomputed kernel matrix instead, shape = (n_samples,\n",
      " |          n_samples_fitted], where n_samples_fitted is the number of\n",
      " |          samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The R2 score used when calling ``score`` on a regressor will use\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with `metrics.r2_score`. This will influence the ``score`` method of\n",
      " |      all the multioutput regressors (except for\n",
      " |      `multioutput.MultiOutputRegressor`). To specify the default value\n",
      " |      manually and avoid the warning, please either call `metrics.r2_score`\n",
      " |      directly or make a custom scorer with `metrics.make_scorer` (the\n",
      " |      built-in scorer ``'r2'`` uses ``multioutput='uniform_average'``).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lreg_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Materials in Midterm Exam end here)**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##  Overview of the whole picture\n",
    "Possible hierarchies of machine learning concepts:\n",
    "\n",
    "- **Problems**: Supervised Learning(Regression,Classification), Unsupervised Learning (Dimension Reduction, Clustering), Reinforcement Learning (Not covered in this course)\n",
    "\n",
    "\n",
    "- **Models**: \n",
    "    - (Supervised) Linear Regression, Logistic Regression, K-Nearest Neighbor (kNN) Classification/Regression, Decision Tree, Random Forest, Support Vector Machine, Ensemble Method, Neural Network...\n",
    "    - (Unsupervised) K-means,Hierachical Clustering, Principle Component Analysis, Manifold Learning (MDS, IsoMap, Diffusion Map, tSNE), Auto Encoder...\n",
    "    \n",
    "\n",
    "- **Algorithms**: Gradient Descent, Stochastic Gradient Descent (SGD), Back Propagation (BP),Expectation–Maximization (EM)...\n",
    "    \n",
    "    \n",
    "For the same **problem**, there may exist multiple **models** to discribe it. Given the specific **model**, there might be many different **algorithms** to solve it.\n",
    "\n",
    "Why there is so much diversity? The following two fundamental principles of machine learning may provide theoretical insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**[Bias-Variance Trade-off](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229)**: Simple models -- large bias, low variance. Complex models -- low bias, large variance\n",
    "\n",
    "**[No Free Lunch Theorem](https://analyticsindiamag.com/what-are-the-no-free-lunch-theorems-in-data-science/#:~:text=Once%20Upon%20A%20Time,that%20they%20brought%20a%20drink)**: (in plain language) There is no one model that works best for every problem. (more quantitatively) Any two models are equivalent when their performance averaged across all possible problems. --Even true for [optimization algorithms](https://en.wikipedia.org/wiki/No_free_lunch_in_search_and_optimization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Regression\n",
    "\n",
    "Recall the basic task of **supervised learning**: given the *training dataset* $(x^{(i)},y^{(i)}), i= 1,2,..., N$ with $y^{(i)}\\in \\mathbb{R}^{q}$ (for simplicity, assume $q=1$) denotes the *labels*, the supervised learning aims to find a mapping $y\\approx\\mathbf{f}(x):\\mathbb{R}^{p}\\to\\mathbb{R}$ that we can use it to make predictions on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Setup\n",
    "\n",
    "#### Model assumption 1: Linear Mapping Assumption.\n",
    "\n",
    "$$y\\approx\\mathbf{f}(x)=\\beta_{0}+\\beta_{1}x_{1}+..+\\beta_{p}x_{p} = \\tilde{x}\\beta,$$  \n",
    "    $$\\tilde{x}=(1,x_{1},..,x_{p})\\in\\mathbb{R}^{1\\times (p+1)},\\beta = (\\beta_{0},\\beta_{1},..,\\beta_{p})^{T}\\in\\mathbb{R}^{(p+1)\\times 1}.$$\n",
    "\n",
    "\n",
    "Here $\\beta$ is called regression coefficients, and $\\beta_{0}$ specially referred to intercept. \n",
    "\n",
    "Using the whole training dataset, we can write as \n",
    "\n",
    "$$Y=\\left(\n",
    " \\begin{matrix}\n",
    "   y^{(1)}\\\\\n",
    "   y^{(2)} \\\\\n",
    "   \\cdots \\\\\n",
    "   y^{(N)}\n",
    "  \\end{matrix} \n",
    "\\right)\\approx\\left(\n",
    "  \\begin{matrix}\n",
    "   \\mathbf{f}(x^{(1)})\\\\\n",
    "   \\mathbf{f}(x^{(2)})\\\\\n",
    "   \\cdots \\\\\n",
    "   \\mathbf{f}(x^{(N)})\n",
    "  \\end{matrix} \n",
    "\\right)=\\left(\n",
    "  \\begin{matrix}\n",
    "   \\tilde{x}^{(1)}\\beta\\\\\n",
    "   \\tilde{x}^{(2)}\\beta\\\\\n",
    "   \\cdots \\\\\n",
    "   \\tilde{x}^{(N)}\\beta\n",
    "  \\end{matrix} \n",
    "\\right)=\\left(\n",
    "  \\begin{matrix}\n",
    "   \\tilde{x}^{(1)}\\\\\n",
    "   \\tilde{x}^{(2)}\\\\\n",
    "   \\cdots \\\\\n",
    "   \\tilde{x}^{(N)}\n",
    "  \\end{matrix} \n",
    "\\right)\\beta = \\tilde{X}\\beta,\n",
    "$$\n",
    "\n",
    "where \n",
    "$$\n",
    "\\tilde{X}=\\left(\n",
    "  \\begin{matrix}\n",
    "   1& x_{1}^{(1)} & \\cdots & x_{p}^{(1)}\\\\\n",
    "   1& x_{1}^{(2)} & \\cdots & x_{p}^{(2)}\\\\\n",
    "   \\cdots \\\\\n",
    "   1& x_{1}^{(N)} & \\cdots & x_{p}^{(N)}\n",
    "  \\end{matrix} \n",
    "\\right)\n",
    "$$\n",
    "is also called the augmented data matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Model assumption 2: Gaussian Residual Assumption ($L^{2}$ loss assumption)\n",
    "$$y^{(i)}=\\tilde{x}^{(i)}\\beta+\\epsilon^{(i)}, i = 1,2,.., N$$\n",
    "The residuals or errors $\\epsilon^{(i)}$ are **assumed** as independent Gaussian random variables with identical distribution $\\mathcal{N}(0,\\sigma^{2})$ which has mean 0 and standard deviation $\\sigma$.\n",
    "\n",
    "From the density function of Gaussian distribution, the prabability to observe $\\epsilon^{(i)}$ within the small interval $[z,z+\\Delta z]$ is roughly $$\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp({-\\frac{z^2}{2\\sigma^2}})\\Delta z.$$\n",
    "\n",
    "From the data, we know indeed $z=y^{(i)}-\\tilde{x}^{(i)}\\beta$. Therefore, given $x^{(i)}$ as fixed, the probability density (likelihood) to observe $y^{(i)}$ is roughly $$l(y^{(i)}|x^{(i)},\\beta)=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp({-\\frac{(y^{(i)}-\\tilde{x}^{(i)}\\beta)^2}{2\\sigma^2}}).$$\n",
    "\n",
    "Using the *independence* assumption, the overall likelihood to observe the response data $y^{i}(i=1,2,...,N)$ is \n",
    "\n",
    "$$\\mathcal{L}(y^{(i)},1\\leq i\\leq N|\\beta,x^{(i)})=\\prod_{i=1}^{N}l(y^{(i)}|x^{(i)},\\beta)$$\n",
    "\n",
    "The famous **Maximum Likelihood Estimation** theory in statistics **assumes** that we aim to find the unknown parameter $\\beta$ that maximizes the $\\mathcal{L}(\\beta;x^{(i)},y^{(i)},1\\leq i\\leq N)$ by treating $x^{(i)}$ and $y^{(i)}$ as fixed numbers. \n",
    "\n",
    "Equivalently, as the function of $\\beta$, we can maximize $$\\ln \\mathcal{L}= \\sum_{i=1}^{N}\\ln l(y^{(i)}|\\beta,x^{(i)}).$$ \n",
    "\n",
    "By removing the constants, we finally arrives at the **minimization** problem of $L^{2}$ loss function \n",
    "$$L(\\beta)=\\sum_{i=1}^{N}(y^{(i)}-\\tilde{x}^{(i)}\\beta)^{2}= ||Y-\\tilde{X}\\beta||_{2}^2.$$\n",
    "\n",
    "The optimal parameter \n",
    "$$\\hat{\\beta}=\\text{argmin} L(\\beta)$$\n",
    "is also called the ordinary least square (OLS) estimator in statistics community.\n",
    "\n",
    "We also have the prediction $$\\hat{y}^{(i)}=\\tilde{x}^{(i)}\\hat{\\beta}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm: Normal Equation\n",
    "\n",
    "To solve the critical points, we have $\\nabla L(\\beta)=0$.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial L}{\\partial \\beta_{0}}&=2\\sum_{i=1}^{N}(\\tilde{x}^{(i)}\\beta-y^{(i)})=0,\\\\\n",
    "\\frac{\\partial L}{\\partial \\beta_{k}}&=2\\sum_{i=1}^{N} x_{k}^{(i)}(\\tilde{x}^{(i)}\\beta-y^{(i)})=0,\\quad k=1,2,..,p.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "In Matrix form, it can be expressed as (left as exercise) $$\\tilde{X}^{T}\\tilde{X}\\beta=\\tilde{X}^{T}Y,$$\n",
    "\n",
    "also called the **normal equation** of linear regression. Then the OLS estimator can be solved as $$\\hat{\\beta}=(\\tilde{X}^{T}\\tilde{X})^{-1}\\tilde{X}^{T}Y.$$\n",
    "\n",
    "**[Geometrical Interpretation](https://en.wikipedia.org/wiki/Ordinary_least_squares)**\n",
    "\n",
    "Denote $\\tilde{X}=(\\tilde{X}_{0},\\tilde{X}_{1},..,\\tilde{X}_{p})$, then $\\tilde{X}\\beta=\\sum_{k=0}^{p}\\beta_{k}\\tilde{X}_{k}$. We require that the residual $Y-\\tilde{X}\\beta$ is vertical to the plane spanned by $\\tilde{X}_{k}$, which yields $$\\tilde{X}_{k}^{T}(Y-\\tilde{X}\\beta)=0,\\quad k = 0,1,...,p$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions: Regularization, Ridge Regression and LASSO\n",
    "\n",
    "Recall the likelihood function -- we interpret it as the probability of observing the response data, given the parameter $\\beta$ as fixed, i.e. conditional probability\n",
    "$$\\mathcal{P}(y^{(i)},1\\leq i\\leq N|\\beta,x^{(i)})=\\prod_{i=1}^{N}l(y^{(i)}|x^{(i)},\\beta)$$\n",
    "\n",
    "Now we take a bayesian approach -- assume $\\beta$ is the random variable with **prior distirbution** $\\mathcal{P}(\\beta)$. Then the **posterior distribution** of $\\beta$ given the data is  $$\\mathcal{P}(\\beta|x^{(i)},y^{(i)},1\\leq i\\leq N)\\propto \\mathcal{P}(\\beta)\\mathcal{P}(y^{(i)},1\\leq i\\leq N|\\beta,x^{(i)}).$$\n",
    "\n",
    "The **Bayesian** estimation aims to maximaze the posterior distribution. Note that \n",
    "\n",
    "$$\\text{argmax}_{\\beta}\\mathcal{P}(\\beta|x^{(i)},y^{(i)},1\\leq i\\leq N)=\\text{argmax}_{\\beta}\\ln\\mathcal{P}(\\beta|x^{(i)},y^{(i)},1\\leq i\\leq N)$$\n",
    "\n",
    "- Case 1: The prior distribution $\\mathcal{P}(\\beta_{i}=x)\\propto \\exp(-x^{2})$ is Gaussian-like, and different $\\beta_{i}$ are independent. Now the minimization problem becomes \n",
    "\n",
    "    $$\\min_{\\beta} ||Y-\\tilde{X}\\beta||_{2}^2+\\lambda||\\beta||_{2}^{2}.$$\n",
    "\n",
    "here $||\\beta||_{2}^{2}=\\sum_{i=0}^{p}\\beta_{i}^{2}.$\n",
    "    This is called **Ridge Regression**. \n",
    "    \n",
    "Here $\\lambda$ is the adjustable parameter in algorithm --  its choice is empirical while sometimes very important for model performance (where the word \"alchemy\" arises in machine learning!!!)\n",
    "\n",
    "\n",
    "- Case 2: The prior distribution $\\mathcal{P}(\\beta_{i}=x)\\propto \\exp(-|x|)$ is double-exponential like, and different $\\beta_{i}$ are independent. Now the minimization problem becomes \n",
    "\n",
    "    $$\\min_{\\beta} ||Y-\\tilde{X}\\beta||_{2}^2+\\lambda\\sum_{i=0}^{p}|\\beta_{i}|$$\n",
    "    \n",
    "    This is called [**LASSO Regression**](https://en.wikipedia.org/wiki/Lasso_(statistics)).\n",
    "    \n",
    "In general, these additional terms are called the **regularization terms**. In statistics, regularization is equivalent to Bayesian prior.\n",
    "\n",
    "Algorithm consideration: The optimization for ridge regression is similar to OLS -- try to derive the analytical solution your self. The optimization for LASSO is [non-trival](https://www.cs.ubc.ca/~schmidtm/Documents/2005_Notes_Lasso.pdf) and is the important topic in convex optimization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Diabetes Dataset\n",
    "\n",
    "We use the [scikit-learn package](https://scikit-learn.org/stable/index.html) to load the data and run regression. More tutorials about linear models can be [found here](https://scikit-learn.org/stable/modules/linear_model.html).\n",
    "\n",
    "Data from [this paper](https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf) by Professor [Robert Tibshirani et al](https://statweb.stanford.edu/~tibs/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "X,y= datasets.load_diabetes(return_X_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_diabetes in module sklearn.datasets.base:\n",
      "\n",
      "load_diabetes(return_X_y=False)\n",
      "    Load and return the diabetes dataset (regression).\n",
      "    \n",
      "    ==============   ==================\n",
      "    Samples total    442\n",
      "    Dimensionality   10\n",
      "    Features         real, -.2 < x < .2\n",
      "    Targets          integer 25 - 346\n",
      "    ==============   ==================\n",
      "    \n",
      "    Read more in the :ref:`User Guide <diabetes_dataset>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    return_X_y : boolean, default=False.\n",
      "        If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "        See below for more information about the `data` and `target` object.\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    data : Bunch\n",
      "        Dictionary-like object, the interesting attributes are:\n",
      "        'data', the data to learn, 'target', the regression target for each\n",
      "        sample, 'data_filename', the physical location\n",
      "        of diabetes data csv dataset, and 'target_filename', the physical\n",
      "        location of diabetes targets csv datataset (added in version `0.20`).\n",
      "    \n",
      "    (data, target) : tuple if ``return_X_y`` is True\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(datasets.load_diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the training and test dataset by random splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 10)\n",
      "(45,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, **options)\n",
      "    Split arrays or matrices into random train and test subsets\n",
      "    \n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float, int or None, optional (default=None)\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float, int, or None, (default=None)\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, optional (default=None)\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "    \n",
      "    shuffle : boolean, optional (default=True)\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like or None (default=None)\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinary Least Square (OLS) Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg_ols = linear_model.LinearRegression()\n",
    "reg_ols.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_decision_function',\n",
       " '_estimator_type',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_preprocess_data',\n",
       " '_residues',\n",
       " '_set_intercept',\n",
       " 'coef_',\n",
       " 'copy_X',\n",
       " 'fit',\n",
       " 'fit_intercept',\n",
       " 'get_params',\n",
       " 'intercept_',\n",
       " 'n_jobs',\n",
       " 'normalize',\n",
       " 'predict',\n",
       " 'rank_',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'singular_']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(reg_ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  19.92576904, -262.55453086,  509.19112446,  336.09693678,\n",
       "       -849.29530342,  480.22076125,  120.68418641,  236.71853501,\n",
       "        716.61035542,   70.41045019])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_ols.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ols = reg_ols.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation:\n",
    "   - Mean Square Error (MSE) -- the lower, the better (in test data):  $\\frac{1}{N}\\sum_{i=1}^{N}(y^{(i)}-\\hat{y}^{(i)})^{2}$\n",
    "   - R-squared (coefficient of determination, $R^{2}$) -- the larger, the better (in test data): $1 - \\frac{\\sum_{i=1}^{N}(y^{(i)}-\\hat{y}^{(i)})^{2}}{\\sum_{i=1}^{N}(y^{(i)}-\\bar{y})^{2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2743.8800467688443 0.5514251914993505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse_ols = mean_squared_error(y_test, y_pred_ols)\n",
    "R2_ols =  reg_ols.score(X_test,y_test)\n",
    "print(mse_ols,R2_ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  21.70557246 -252.8105591   507.97196544  328.21420703 -280.47609687\n",
      "   37.89517179 -127.46013757  163.28415598  497.87046059   77.00701528]\n",
      "2735.677504142064 0.5527661590071538\n"
     ]
    }
   ],
   "source": [
    "reg_ridge = linear_model.Ridge(alpha=.02)\n",
    "reg_ridge.fit(X_train,y_train)\n",
    "print(reg_ridge.coef_)\n",
    "y_pred_ridge = reg_ridge.predict(X_test)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "R2_ridge =  reg_ridge.score(X_test,y_test)\n",
    "print(mse_ridge,R2_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.         -212.76030063  514.23777918  309.6748151  -131.90735899\n",
      "   -0.         -215.96745627   34.17218616  479.55741824   61.49888891]\n",
      "2650.840160539063 0.5666355317609787\n"
     ]
    }
   ],
   "source": [
    "reg_lasso = linear_model.Lasso(alpha=.05)\n",
    "reg_lasso.fit(X_train,y_train)\n",
    "print(reg_lasso.coef_)\n",
    "\n",
    "y_pred_lasso = reg_lasso.predict(X_test)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "R2_lasso =  reg_lasso.score(X_test,y_test)\n",
    "print(mse_lasso,R2_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5125152248773208\n",
      "0.5102072320833589\n",
      "0.5072801848497961\n"
     ]
    }
   ],
   "source": [
    "print(reg_ols.score(X_train,y_train))\n",
    "print(reg_ridge.score(X_train,y_train))\n",
    "print(reg_lasso.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition, OLS has the smallest MSE (largest R-squared) on **training dataset**. What about on the test dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_errors = list()\n",
    "test_errors = list()\n",
    "alphas = np.logspace(-5, -1, 20)\n",
    "for alpha in alphas:\n",
    "    reg_lasso.set_params(alpha=alpha) # change the parameter of reg_lasso\n",
    "    reg_lasso.fit(X_train, y_train)\n",
    "    train_errors.append(reg_lasso.score(X_train, y_train))\n",
    "    test_errors.append(reg_lasso.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17eeb55b6c8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(dpi=100)\n",
    "plt.semilogx(alphas,train_errors,label = 'train R2')\n",
    "plt.semilogx(alphas,test_errors,label = 'test R2')\n",
    "plt.xlabel('alpha')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Cross Validation](https://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores_lasso = cross_val_score(reg_lasso, X, y, cv=10)\n",
    "scores_ridge = cross_val_score(reg_ridge, X, y, cv=10)\n",
    "scores_ols = cross_val_score(reg_ols, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51664361 0.23697943 0.38986711 0.59566023 0.27488654 0.62341628\n",
      " 0.4517201  0.44589908 0.42566583 0.67093632]\n",
      "[0.54226962 0.2468243  0.37346034 0.61151627 0.27431857 0.62361487\n",
      " 0.42810656 0.42385301 0.42860824 0.67812054]\n",
      "[0.55614411 0.23056092 0.35357777 0.62190498 0.26587602 0.61819338\n",
      " 0.41815916 0.43515232 0.43436983 0.68568514]\n"
     ]
    }
   ],
   "source": [
    "print(scores_lasso)\n",
    "print(scores_ridge)\n",
    "print(scores_ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cross_val_score in module sklearn.model_selection._validation:\n",
      "\n",
      "cross_val_score(estimator, X, y=None, groups=None, scoring=None, cv='warn', n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score='raise-deprecating')\n",
      "    Evaluate a score by cross-validation\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    estimator : estimator object implementing 'fit'\n",
      "        The object to use to fit the data.\n",
      "    \n",
      "    X : array-like\n",
      "        The data to fit. Can be for example a list, or an array.\n",
      "    \n",
      "    y : array-like, optional, default: None\n",
      "        The target variable to try to predict in the case of\n",
      "        supervised learning.\n",
      "    \n",
      "    groups : array-like, with shape (n_samples,), optional\n",
      "        Group labels for the samples used while splitting the dataset into\n",
      "        train/test set. Only used in conjunction with a \"Group\" `cv` instance\n",
      "        (e.g., `GroupKFold`).\n",
      "    \n",
      "    scoring : string, callable or None, optional, default: None\n",
      "        A string (see model evaluation documentation) or\n",
      "        a scorer callable object / function with signature\n",
      "        ``scorer(estimator, X, y)`` which should return only\n",
      "        a single value.\n",
      "    \n",
      "        Similar to :func:`cross_validate`\n",
      "        but only a single metric is permitted.\n",
      "    \n",
      "        If None, the estimator's default scorer (if available) is used.\n",
      "    \n",
      "    cv : int, cross-validation generator or an iterable, optional\n",
      "        Determines the cross-validation splitting strategy.\n",
      "        Possible inputs for cv are:\n",
      "    \n",
      "        - None, to use the default 3-fold cross validation,\n",
      "        - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      "        - :term:`CV splitter`,\n",
      "        - An iterable yielding (train, test) splits as arrays of indices.\n",
      "    \n",
      "        For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      "        either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "        other cases, :class:`KFold` is used.\n",
      "    \n",
      "        Refer :ref:`User Guide <cross_validation>` for the various\n",
      "        cross-validation strategies that can be used here.\n",
      "    \n",
      "        .. versionchanged:: 0.20\n",
      "            ``cv`` default value if None will change from 3-fold to 5-fold\n",
      "            in v0.22.\n",
      "    \n",
      "    n_jobs : int or None, optional (default=None)\n",
      "        The number of CPUs to use to do the computation.\n",
      "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "        for more details.\n",
      "    \n",
      "    verbose : integer, optional\n",
      "        The verbosity level.\n",
      "    \n",
      "    fit_params : dict, optional\n",
      "        Parameters to pass to the fit method of the estimator.\n",
      "    \n",
      "    pre_dispatch : int, or string, optional\n",
      "        Controls the number of jobs that get dispatched during parallel\n",
      "        execution. Reducing this number can be useful to avoid an\n",
      "        explosion of memory consumption when more jobs get dispatched\n",
      "        than CPUs can process. This parameter can be:\n",
      "    \n",
      "            - None, in which case all the jobs are immediately\n",
      "              created and spawned. Use this for lightweight and\n",
      "              fast-running jobs, to avoid delays due to on-demand\n",
      "              spawning of the jobs\n",
      "    \n",
      "            - An int, giving the exact number of total jobs that are\n",
      "              spawned\n",
      "    \n",
      "            - A string, giving an expression as a function of n_jobs,\n",
      "              as in '2*n_jobs'\n",
      "    \n",
      "    error_score : 'raise' | 'raise-deprecating' or numeric\n",
      "        Value to assign to the score if an error occurs in estimator fitting.\n",
      "        If set to 'raise', the error is raised.\n",
      "        If set to 'raise-deprecating', a FutureWarning is printed before the\n",
      "        error is raised.\n",
      "        If a numeric value is given, FitFailedWarning is raised. This parameter\n",
      "        does not affect the refit step, which will always raise the error.\n",
      "        Default is 'raise-deprecating' but from version 0.22 it will change\n",
      "        to np.nan.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    scores : array of float, shape=(len(list(cv)),)\n",
      "        Array of scores of the estimator for each run of the cross validation.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn import datasets, linear_model\n",
      "    >>> from sklearn.model_selection import cross_val_score\n",
      "    >>> diabetes = datasets.load_diabetes()\n",
      "    >>> X = diabetes.data[:150]\n",
      "    >>> y = diabetes.target[:150]\n",
      "    >>> lasso = linear_model.Lasso()\n",
      "    >>> print(cross_val_score(lasso, X, y, cv=3))  # doctest: +ELLIPSIS\n",
      "    [0.33150734 0.08022311 0.03531764]\n",
      "    \n",
      "    See Also\n",
      "    ---------\n",
      "    :func:`sklearn.model_selection.cross_validate`:\n",
      "        To run cross-validation on multiple metrics and also to return\n",
      "        train scores, fit times and score times.\n",
      "    \n",
      "    :func:`sklearn.model_selection.cross_val_predict`:\n",
      "        Get predictions from each split of cross-validation for diagnostic\n",
      "        purposes.\n",
      "    \n",
      "    :func:`sklearn.metrics.make_scorer`:\n",
      "        Make a scorer from a performance metric or loss function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lasso</th>\n",
       "      <th>ols</th>\n",
       "      <th>ridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.516644</td>\n",
       "      <td>0.556144</td>\n",
       "      <td>0.542270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.236979</td>\n",
       "      <td>0.230561</td>\n",
       "      <td>0.246824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.389867</td>\n",
       "      <td>0.353578</td>\n",
       "      <td>0.373460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.595660</td>\n",
       "      <td>0.621905</td>\n",
       "      <td>0.611516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.274887</td>\n",
       "      <td>0.265876</td>\n",
       "      <td>0.274319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.623416</td>\n",
       "      <td>0.618193</td>\n",
       "      <td>0.623615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.451720</td>\n",
       "      <td>0.418159</td>\n",
       "      <td>0.428107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.445899</td>\n",
       "      <td>0.435152</td>\n",
       "      <td>0.423853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.425666</td>\n",
       "      <td>0.434370</td>\n",
       "      <td>0.428608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.670936</td>\n",
       "      <td>0.685685</td>\n",
       "      <td>0.678121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lasso       ols     ridge\n",
       "0  0.516644  0.556144  0.542270\n",
       "1  0.236979  0.230561  0.246824\n",
       "2  0.389867  0.353578  0.373460\n",
       "3  0.595660  0.621905  0.611516\n",
       "4  0.274887  0.265876  0.274319\n",
       "5  0.623416  0.618193  0.623615\n",
       "6  0.451720  0.418159  0.428107\n",
       "7  0.445899  0.435152  0.423853\n",
       "8  0.425666  0.434370  0.428608\n",
       "9  0.670936  0.685685  0.678121"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "scores_all = pd.DataFrame({\"lasso\": scores_lasso,\"ols\": scores_ols, \"ridge\":scores_ridge})\n",
    "scores_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides mean and standard deviation, we can also use the [boxplot](https://towardsdatascience.com/understanding-boxplots-5e2df7bcbd51) to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17eed1de588>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(dpi=100)\n",
    "sns.boxplot(data = scores_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
